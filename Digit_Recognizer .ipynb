{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import optim,nn\n",
    "from torchsummary import summary \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "               \n",
    "        image = item[1:].values.astype(np.uint8).reshape((28, 28))\n",
    "        label = item[0]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.ToPILImage(),transforms.Pad(2),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "transform_valid = transforms.Compose([transforms.ToPILImage(),transforms.Pad(2),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.15\n",
    "indicies = len(dataset)\n",
    "r = list(range(indicies))\n",
    "np.random.shuffle(r)\n",
    "split = int(np.floor(valid_size * indicies))\n",
    "train_idx, valid_idx = r[split:],r[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(dataset, transform = transform_train)\n",
    "valid_train = Data(dataset,transform = transform_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size = 64 , sampler = train_sampler)\n",
    "validloader = torch.utils.data.DataLoader(valid_train, batch_size = 64, sampler = valid_sampler)\n",
    "\n",
    "data = iter(trainloader)\n",
    "X, Y = data.next()\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length train: {len(train_idx)}\")\n",
    "print(f\"Length valid: {len(valid_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig, axis = plt.subplots(3, 10, figsize=(15, 10))\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "for i, ax in enumerate(axis.flat):\n",
    "    with torch.no_grad():\n",
    "        image, label = images[i], labels[i]\n",
    "\n",
    "        ax.imshow(image.view(28, 28), cmap='binary') # add image\n",
    "        ax.set(title = f\"{label}\") # add label\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2 ,stride = 2 )\n",
    "        self.dropout = nn.Dropout(p = 0.4)\n",
    "\n",
    "        self.L = nn.Conv2d( in_channels = 1, out_channels = 4, kernel_size=(3,3),padding= 1)\n",
    "        self.L1 = nn.Conv2d(in_channels = 5, out_channels = 4, kernel_size=(3,3),padding = 1 )\n",
    "        self.L2 = nn.Conv2d(in_channels = 9, out_channels = 4, kernel_size=(3,3),padding = 1)\n",
    "        self.L3 = nn.Conv2d(in_channels = 13, out_channels = 4, kernel_size=(3,3),padding = 1 )\n",
    "        self.L4 = nn.Conv2d(in_channels = 17, out_channels = 4, kernel_size=(3,3),padding = 1 )\n",
    "       \n",
    "\n",
    "        self.batchnorm_c1 = nn.BatchNorm2d(5)\n",
    "        self.batchnorm_c2 = nn.BatchNorm2d(9)\n",
    "        self.batchnorm_c3 = nn.BatchNorm2d(13)\n",
    "        self.batchnorm_c4 = nn.BatchNorm2d(17)\n",
    "        self.batchnorm_c5 = nn.BatchNorm2d(21)\n",
    "       \n",
    "        self.dropout1 = nn.Dropout(p = 0.4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 21, out_channels = 32, kernel_size = (3,3),padding = 1,stride = 1 )\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size= (3,3), stride = 1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size= (3,3),padding =1,stride = 1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.linear1 = nn.Linear(128*3*3,120)\n",
    "        self.linear2 = nn.Linear(120,84)\n",
    "        self.linear3 = nn.Linear(84,64)\n",
    "        self.linear4 = nn.Linear(64,10)\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "        z0 = self.L(X)\n",
    "        z0c = torch.cat((X,z0),dim=1)\n",
    "        z0b = self.batchnorm_c1(z0c)\n",
    "        a0 = F.relu(z0b)\n",
    "\n",
    "        z1 = self.L1(a0)\n",
    "        z1c = torch.cat((X,z0,z1),dim = 1)\n",
    "        z1b = self.batchnorm_c2(z1c)\n",
    "        a1 = F.relu(z1b)\n",
    "\n",
    "        z2 = self.L2(a1)\n",
    "        z2c = torch.cat((X,z0,z1,z2),dim = 1)\n",
    "        z2b = self.batchnorm_c3(z2c)\n",
    "        a2 = F.relu(z2b)\n",
    "\n",
    "        z3 = self.L3(a2)\n",
    "        z3c = torch.cat((X,z0,z1,z2,z3),dim = 1)\n",
    "        z3b = self.batchnorm_c4(z3c)\n",
    "        a3 = F.relu(z3b)\n",
    "\n",
    "        z4 = self.L4(a3)\n",
    "        z4c = torch.cat((X,z0,z1,z2,z3,z4),dim = 1)\n",
    "        z4b = F.dropout(self.batchnorm_c5(z4c))\n",
    "        a4 = F.relu(z4b)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        z11 = self.conv1(a4)\n",
    "        a11 = self.pool(self.dropout(self.batchnorm1(F.relu(z11))))\n",
    "\n",
    "        z22 = self.conv2(a11)\n",
    "        a22 = self.pool(self.dropout(self.batchnorm2(F.relu(z22))))\n",
    "\n",
    "        z33 = self.conv3(a22)\n",
    "        a33 = self.pool(self.dropout(self.batchnorm3(F.relu(z33))))\n",
    "\n",
    "\n",
    "        a33 = a33.view(a33.shape[0],-1)\n",
    "\n",
    "        a44 = self.dropout(F.relu(self.linear1(a33)))\n",
    "        a55 = self.dropout(F.relu(self.linear2(a44))) \n",
    "        a66 = self.dropout(F.relu(self.linear3(a55)))\n",
    "        a77 = F.log_softmax(self.linear4(a66), dim = 1)\n",
    "\n",
    "\n",
    "        return a77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,input_size=(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "alpha = 0.001\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_data = []\n",
    "valid_loss_data = []\n",
    "train_acc_data = []\n",
    "valid_acc_data = []\n",
    "\n",
    "for e in range(epoch):\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    train_acc  = 0\n",
    "    valid_acc  = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for images,labels in trainloader:\n",
    "        \n",
    "        image = images.cuda()\n",
    "        label = labels.cuda()\n",
    "\n",
    "        logps = model(image)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(logps,label.squeeze())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * image.size(0)\n",
    "        \n",
    "        ps = torch.exp(logps)\n",
    "        top_p,top_class = ps.topk(1,dim=1)\n",
    "        T_equals = top_class == label.view(*top_class.shape)\n",
    "        \n",
    "        train_acc += torch.mean(T_equals.type(torch.FloatTensor))\n",
    "        \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for images,labels in validloader:\n",
    "        image = images.cuda()\n",
    "        label = labels.cuda()\n",
    "        \n",
    "        logps = model(image)\n",
    "        loss = criterion(logps,label)\n",
    "        valid_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        ps = torch.exp(logps)\n",
    "        top_p,top_class = ps.topk(1,dim=1)\n",
    "\n",
    "        equals = top_class == label.view(*top_class.shape)\n",
    "        valid_acc += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "    train_loss = train_loss/len(trainloader.sampler)\n",
    "    valid_loss = valid_loss/len(validloader.sampler)\n",
    "    train_acc = train_acc/len(trainloader)\n",
    "    valid_acc = valid_acc/len(validloader)\n",
    "    \n",
    "    train_loss_data.append(train_loss)\n",
    "    valid_loss_data.append(valid_loss)\n",
    "    train_acc_data.append(train_acc)\n",
    "    valid_acc_data.append(valid_acc)\n",
    "    \n",
    "    \n",
    "    print(\"Epoch : {} Training Loss : {:.6f} Validation Loss : {:.6f} Traning Accuracy : {:.3f} Validation Accuracy : {:.3f}\".format(e+1,train_loss,valid_loss,train_acc,valid_acc))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSubmissionMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.data.iloc[index].values.astype(np.uint8).reshape((28, 28))\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "submissionset = DatasetSubmissionMNIST(test_data, transform=transform)\n",
    "submissionloader = torch.utils.data.DataLoader(submissionset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(submissionloader)\n",
    "X = data.next()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = [['ImageId', 'Label']]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    image_id = 1\n",
    "\n",
    "    for images in submissionloader:\n",
    "        \n",
    "        images = images.cuda()\n",
    "        log_ps = model(images)\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        \n",
    "        for prediction in top_class:\n",
    "            submission.append([image_id, prediction.item()])\n",
    "            image_id += 1\n",
    "            \n",
    "print(len(submission) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('submission.csv', 'w') as submissionFile:\n",
    "    writer = csv.writer(submissionFile)\n",
    "    writer.writerows(submission)\n",
    "    \n",
    "print('Submission Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
